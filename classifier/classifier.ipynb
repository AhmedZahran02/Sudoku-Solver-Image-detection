{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "import skimage as sk\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pandas as panda\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img_size = (32, 32)\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanImage(image, label = \"\"):\n",
    "    # threshold = sk.filters.threshold_otsu(image)\n",
    "\n",
    "    threshold = 0.5\n",
    "    image = sk.transform.resize(image, target_img_size, mode='reflect', anti_aliasing=True)\n",
    "\n",
    "    # print(np.histogram(image.flatten()))\n",
    "    if np.max(image) <= 1 and threshold > 1:\n",
    "        threshold = threshold / 255\n",
    "    \n",
    "    \n",
    "    image[image > threshold] = 1\n",
    "    image[image <= threshold] = 0\n",
    "\n",
    "    # image = sk.morphology.skeletonize(image)\n",
    "\n",
    "    # if (random.random() > 0.9 and label != \"\") :\n",
    "    # sk.io.imshow(image)\n",
    "    # sk.io.show()\n",
    "\n",
    "    # if image.dtype != np.uint8:\n",
    "    #     image = image.astype(np.uint8)\n",
    "\n",
    "    # image = cv2.Canny(image, 0.5 * threshold, threshold)\n",
    "        \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.uint8(img)\n",
    "\n",
    "    win_size = (16, 16)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(feature_set='hog'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames = os.listdir(path_to_dataset)\n",
    "\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        if fn.split('.')[-1] != 'jpg':\n",
    "            continue\n",
    "\n",
    "        label = fn.split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        path = os.path.join(path_to_dataset, fn)\n",
    "        img = cv2.imread(path)\n",
    "        features.append(extract_features(img, feature_set))\n",
    "        \n",
    "        # show an update every 1,000 images\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i, len(img_filenames)))\n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(train_images)):\n",
    "        features.append(extract_features(train_images[i]))\n",
    "        labels.append(train_labels[i])\n",
    "    \n",
    "    for i in range(len(test_images)):\n",
    "        features.append(extract_features(test_images[i]))\n",
    "        labels.append(test_labels[i])\n",
    "    return features, labels      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(features, labels):\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "    print(\"############## Training ##############\")\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Test the model on images it hasn't seen before\n",
    "    accuracy = classifier.score(test_features, test_labels)\n",
    "    \n",
    "    print('accuracy:', accuracy*100, '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Training ##############\n",
      "accuracy: 98.55000000000001 %\n"
     ]
    }
   ],
   "source": [
    "train_model(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberFromImage(img):\n",
    "    img = cleanImage(img)\n",
    "    result = classifier.predict([extract_features(img)])\n",
    "    return result[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n"
     ]
    }
   ],
   "source": [
    "test_image = sk.io.imread(\"./test8.png\")\n",
    "test_image = cleanImage(test_image)\n",
    "result = classifier.predict([extract_features(test_image)])\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
